{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cce208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (if not installed)\n",
    "!pip install aif360 pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# setting up the environment\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess the dataset \n",
    "import pandas as pd\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "def default_preprocessing(df):\n",
    "    \"\"\"Perform the same preprocessing as the original analysis:\n",
    "    https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb\n",
    "    \"\"\"\n",
    "    return df[(df.days_b_screening_arrest <= 30)\n",
    "            & (df.days_b_screening_arrest >= -30)\n",
    "            & (df.is_recid != -1)\n",
    "            & (df.c_charge_degree != 'O')\n",
    "            & (df.score_text != 'N/A')]\n",
    "\n",
    "# Load COMPAS dataset from local file\n",
    "df = pd.read_csv('compas-scores-two-years.csv', index_col='id')\n",
    "\n",
    "# Create StandardDataset\n",
    "dataset = StandardDataset(df, \n",
    "                          label_name='two_year_recid', \n",
    "                          favorable_classes=[0], \n",
    "                          protected_attribute_names=['sex', 'race'], \n",
    "                          privileged_classes=[['Female'], ['Caucasian']], \n",
    "                          categorical_features=['age_cat', 'c_charge_degree', 'c_charge_desc'], \n",
    "                          features_to_keep=['sex', 'age', 'age_cat', 'race', \n",
    "                                            'juv_fel_count', 'juv_misd_count', 'juv_other_count', \n",
    "                                            'priors_count', 'c_charge_degree', 'c_charge_desc', \n",
    "                                            'two_year_recid'], \n",
    "                          custom_preprocessing=default_preprocessing)\n",
    "\n",
    "# Split into training and test sets\n",
    "train, test = dataset.split([0.7], shuffle=True)\n",
    "\n",
    "# Identify protected attribute\n",
    "protected_attr = 'race'\n",
    "privileged_groups = [{'race': 1}]  # White\n",
    "unprivileged_groups = [{'race': 0}]  # Black\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fairness metrics \n",
    "# Basic dataset metric\n",
    "metric_train = BinaryLabelDatasetMetric(train,\n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Mean difference (favours white if positive):\", metric_train.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b259b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply reweighing to mitigate bias\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "train_transf = RW.fit_transform(train)\n",
    "\n",
    "# Compute fairness metrics after reweighing\n",
    "metric_transf = BinaryLabelDatasetMetric(train_transf,\n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "print(\"Mean difference after reweighing:\", metric_transf.mean_difference())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize Bias\n",
    "# Plot false positive rates by race\n",
    "fpr_by_race = train.labels.ravel()\n",
    "race_groups = train.protected_attributes.ravel()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(['Black', 'White'], [fpr_by_race[race_groups==0].mean(),\n",
    "                             fpr_by_race[race_groups==1].mean()],\n",
    "        color=['red', 'blue'])\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.title('FPR by Race in COMPAS Dataset')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compasDataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
